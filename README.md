# Dockerized Groq AI Chat Application

This repository contains my **end-to-end implementation** of a **Dockerized AI Chat Application powered by Groq**.  
I built this project to gain practical experience in **integrating high-performance LLM APIs**, managing secrets securely, and deploying AI workloads using **Docker**.

All application logic, Docker configuration, and runtime testing were **designed, implemented, and validated by me** as part of my hands-on learning.

---

## ğŸ“Œ Project Highlights

- Groq-powered AI chat using LLM inference
- Secure API key handling via environment variables
- Fully containerized using Docker
- Simple, reproducible, and deployment-ready setup
- Focused on DevOps-friendly AI deployment practices

---

## ğŸ§  Why This Project?

Modern AI applications demand:
- Low latency inference
- Consistent runtime environments
- Easy deployment and portability

This project demonstrates how **Groqâ€™s fast inference capabilities** can be packaged into a **Dockerized application**, making it suitable for real-world deployments and scalable environments.

---

## âš™ï¸ Prerequisites

Before running this project, ensure you have:

- **Python 3.11 or higher**
- **Docker installed and running**
- **Groq API Key** (generated from the Groq platform)

---

## ğŸ—ï¸ Application Architecture

```

User Prompt
â”‚
â–¼
Chat Application (Python)
â”‚
â–¼
Groq API (LLM Inference)
â”‚
â–¼
AI Response

```

The entire application is packaged and executed inside a Docker container for consistency.

---

## ğŸ§° Tech Stack

- **Language:** Python
- **AI Provider:** Groq API
- **Framework:** Streamlit (for chat interface)
- **Containerization:** Docker
- **Secrets Management:** Environment Variables
- **Version Control:** Git & GitHub

---

## ğŸ“‚ Repository Structure

```

Dockerized-Groq-AI-Chat-App/
â”‚
â”œâ”€â”€ Chat-App/
â”‚   â”œâ”€â”€ main.py            # Chat application logic
â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
â”‚   â”œâ”€â”€ Dockerfile        # Docker build instructions
â”‚   â””â”€â”€ docker.sh         # Docker run script
â”‚
â”œâ”€â”€ .env.example           # Sample environment file
â”œâ”€â”€ README.md              # Documentation

```

---

## ğŸ” Environment Configuration

To keep credentials secure, the Groq API key is injected using environment variables.

Create a `.env` file in the project root:

```

GROQ_API_KEY=your_groq_api_key_here

````

---

## ğŸ Local Setup (Without Docker)

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/Dockerized-Groq-AI-Chat-App.git
cd Dockerized-Groq-AI-Chat-App
```` 

### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate    # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r Chat-App/requirements.txt
```

### 4ï¸âƒ£ Run the Application

```bash
cd Chat-App
streamlit run main.py
```

---

## ğŸ³ Docker Deployment

I containerized the application to ensure portability and consistent execution across environments.

### Option 1: Using Shell Script

```bash
cd Chat-App
export GROQ_API_KEY=your_groq_api_key_here
./docker.sh
```

### Option 2: Manual Docker Commands

```bash
cd Chat-App
docker build -t groq-chat-app .
docker run -p 8501:8501 -e GROQ_API_KEY=your_groq_api_key_here groq-chat-app
```

Once the container starts, the chat interface will be accessible via the exposed port.

---

## ğŸ§ª Testing & Validation

I personally tested this application by:

* Running it locally and inside Docker
* Validating Groq API responses
* Restarting containers to ensure stateless execution
* Verifying environment variable injection

---

## ğŸ“ˆ Key Learnings

This project helped me gain hands-on experience in:

* Deploying LLM-backed applications
* Dockerizing AI workloads
* Managing secrets securely
* Building reproducible DevOps workflows
* Understanding AI inference performance in real deployments

---

## ğŸ”® Future Enhancements

* Kubernetes deployment
* CI/CD pipeline integration
* Multi-model Groq support
* Logging and monitoring
* Authentication layer

---

## ğŸ“œ Reference & Acknowledgement

This project was **fully implemented by me**.
I referred to the following repository for **conceptual understanding and general setup ideas**:

* Reference Repository: [](https://github.com/Naveen15github/Dockerized-Groq-AI-Chat-App.git)

All customization, Dockerization, and implementation decisions were independently carried out.

---

## ğŸ‘¤ Author

**Naveen G**
Cloud | DevOps | AI Infrastructure
GitHub: [https://github.com/your-Naveen15github](https://github.com/Naveen15github)
LinkedIn: [https://linkedin.com/in/Naveen G](https://www.linkedin.com/in/naveen-g-41a041253?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3BxpZxBAIJSVCPf%2FWXfnGRVw%3D%3D)

```



